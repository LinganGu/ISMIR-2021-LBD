{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "j6fTAqAXDO_3",
    "outputId": "627d9657-81ef-4410-ee26-d64455c17526",
    "cell_id": "00000-57f20b00-5db1-4694-9c61-e585c7f3fed6",
    "deepnote_cell_type": "code"
   },
   "source": "import io\n\nimport os\n\nimport sys\n\nimport string\n\nimport numpy as np\n\nimport pandas as pd\n\nfrom tensorflow import keras\n\nfrom __future__ import print_function\n\nfrom tensorflow.keras.models import Sequential\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding\n\n\ntranslator = str.maketrans('', '', string.punctuation)\n\ndf = pd.read_csv(\"/content/drive/MyDrive/RapLyrics/PopRap-Male/PopRap-Male.csv\", sep=\"\\t\")\n\ndf.head()\n\n",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>lyrics</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5ueUywJbmAZY2MF9hdJS2y</td>\n      <td>[\"[Verse 1]\\nI got a funny feelin'\\nThe moment...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49X0LAl6faAusYq02PRAY6</td>\n      <td>[\"Intéressé(e) par l'explication des paroles d...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3HPx8VWi8spiBTcGeWGP7h</td>\n      <td>['[Intro]\\nThey make me sick\\nI know I feel yo...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5jDnI5jmAqpvKwmpXP7VSj</td>\n      <td>[\"[Verse 1]\\nI can hear the neighbors\\nThey're...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7Hgcw6qYU1ukRdRGvEkJk3</td>\n      <td>['He promised her a new and better life out in...</td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  song_id                                             lyrics\n0  5ueUywJbmAZY2MF9hdJS2y  [\"[Verse 1]\\nI got a funny feelin'\\nThe moment...\n1  49X0LAl6faAusYq02PRAY6  [\"Intéressé(e) par l'explication des paroles d...\n2  3HPx8VWi8spiBTcGeWGP7h  ['[Intro]\\nThey make me sick\\nI know I feel yo...\n3  5jDnI5jmAqpvKwmpXP7VSj  [\"[Verse 1]\\nI can hear the neighbors\\nThey're...\n4  7Hgcw6qYU1ukRdRGvEkJk3  ['He promised her a new and better life out in..."
     },
     "metadata": {},
     "execution_count": 1
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "0PT70XEuCTWw",
    "outputId": "2d093b0b-f531-40db-dea6-e8d8225a2c4e",
    "cell_id": "00001-0fcf271f-e7ab-481e-bc72-6c2822387970",
    "deepnote_cell_type": "code"
   },
   "source": "pdf = pd.read_csv('/content/drive/MyDrive/RapLyrics/PoetryFoundationData.csv',quotechar='\"')\n\npdf.head()",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Unnamed: 0</th>\n      <th>Title</th>\n      <th>Poem</th>\n      <th>Poet</th>\n      <th>Tags</th>\n      <th>Unnamed: 5</th>\n      <th>Unnamed: 6</th>\n      <th>Unnamed: 7</th>\n      <th>Unnamed: 8</th>\n      <th>Unnamed: 9</th>\n      <th>Unnamed: 10</th>\n      <th>Unnamed: 11</th>\n      <th>Unnamed: 12</th>\n      <th>Unnamed: 13</th>\n      <th>Unnamed: 14</th>\n      <th>Unnamed: 15</th>\n      <th>Unnamed: 16</th>\n      <th>Unnamed: 17</th>\n      <th>Unnamed: 18</th>\n      <th>Unnamed: 19</th>\n      <th>Unnamed: 20</th>\n      <th>Unnamed: 21</th>\n      <th>Unnamed: 22</th>\n      <th>Unnamed: 23</th>\n      <th>Unnamed: 24</th>\n      <th>Unnamed: 25</th>\n      <th>Unnamed: 26</th>\n      <th>Unnamed: 27</th>\n      <th>Unnamed: 28</th>\n      <th>Unnamed: 29</th>\n      <th>Unnamed: 30</th>\n      <th>Unnamed: 31</th>\n      <th>Unnamed: 32</th>\n      <th>Unnamed: 33</th>\n      <th>Unnamed: 34</th>\n      <th>Unnamed: 35</th>\n      <th>Unnamed: 36</th>\n      <th>Unnamed: 37</th>\n      <th>Unnamed: 38</th>\n      <th>Unnamed: 39</th>\n      <th>...</th>\n      <th>Unnamed: 292</th>\n      <th>Unnamed: 293</th>\n      <th>Unnamed: 294</th>\n      <th>Unnamed: 295</th>\n      <th>Unnamed: 296</th>\n      <th>Unnamed: 297</th>\n      <th>Unnamed: 298</th>\n      <th>Unnamed: 299</th>\n      <th>Unnamed: 300</th>\n      <th>Unnamed: 301</th>\n      <th>Unnamed: 302</th>\n      <th>Unnamed: 303</th>\n      <th>Unnamed: 304</th>\n      <th>Unnamed: 305</th>\n      <th>Unnamed: 306</th>\n      <th>Unnamed: 307</th>\n      <th>Unnamed: 308</th>\n      <th>Unnamed: 309</th>\n      <th>Unnamed: 310</th>\n      <th>Unnamed: 311</th>\n      <th>Unnamed: 312</th>\n      <th>Unnamed: 313</th>\n      <th>Unnamed: 314</th>\n      <th>Unnamed: 315</th>\n      <th>Unnamed: 316</th>\n      <th>Unnamed: 317</th>\n      <th>Unnamed: 318</th>\n      <th>Unnamed: 319</th>\n      <th>Unnamed: 320</th>\n      <th>Unnamed: 321</th>\n      <th>Unnamed: 322</th>\n      <th>Unnamed: 323</th>\n      <th>Unnamed: 324</th>\n      <th>Unnamed: 325</th>\n      <th>Unnamed: 326</th>\n      <th>Unnamed: 327</th>\n      <th>Unnamed: 328</th>\n      <th>Unnamed: 329</th>\n      <th>Unnamed: 330</th>\n      <th>Unnamed: 331</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0.0</td>\n      <td>\\r\\r\\n                    Objects Used to Prop...</td>\n      <td>\\r\\r\\nDog bone, stapler,\\r\\r\\ncribbage board, ...</td>\n      <td>Michelle Menting</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1.0</td>\n      <td>\\r\\r\\n                    The New Church\\r\\r\\n...</td>\n      <td>\\r\\r\\nThe old cupola glinted above the clouds,...</td>\n      <td>Lucia Cherciu</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2.0</td>\n      <td>\\r\\r\\n                    Look for Me\\r\\r\\n   ...</td>\n      <td>\\r\\r\\nLook for me under the hood\\r\\r\\nof that ...</td>\n      <td>Ted Kooser</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3.0</td>\n      <td>\\r\\r\\n                    Wild Life\\r\\r\\n     ...</td>\n      <td>\\r\\r\\nBehind the silo, the Mother Rabbit\\r\\r\\n...</td>\n      <td>Grace Cavalieri</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4.0</td>\n      <td>\\r\\r\\n                    Umbrella\\r\\r\\n      ...</td>\n      <td>\\r\\r\\nWhen I push your button\\r\\r\\nyou fly off...</td>\n      <td>Connie Wanek</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>...</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 332 columns</p>\n</div>",
      "text/plain": "   Unnamed: 0  ... Unnamed: 331\n0         0.0  ...          NaN\n1         1.0  ...          NaN\n2         2.0  ...          NaN\n3         3.0  ...          NaN\n4         4.0  ...          NaN\n\n[5 rows x 332 columns]"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "AhhX7KFpD5yT",
    "outputId": "57df5b50-1fd2-4b5d-8293-1eed75c636e5",
    "cell_id": "00002-18eed563-8c8e-41ec-9dea-b71ac8b540c1",
    "deepnote_cell_type": "code"
   },
   "source": "def split_text(x):\n\n   text = x['lyrics']\n   x = str(x)\n\n   sections = str(text).split('\\\\n\\\\n')\n\n   keys = {'Verse 1': np.nan,'Verse 2':np.nan,'Verse 3':np.nan,'Verse 4':np.nan, 'Chorus':np.nan}\n\n   lyrics = str()\n\n   single_text = []\n\n   res = {}\n\n   for s in sections:\n\n       key = s[s.find('[') + 1:s.find(']')].strip()\n\n       if ':' in key:\n\n           key = key[:key.find(':')]\n          \n\n       if key in keys:\n\n           single_text += [x.lower().replace('(','').replace(')','').translate(translator) for x in s[s.find(']')+1:].split('\\\\n') if len(x) > 1]\n          \n\n       res['single_text'] =  ' \\n '.join(single_text)\n\n   return pd.Series(res)\n\n\ndf = df.join( df.apply(split_text, axis=1))\n\ndf.head()",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>lyrics</th>\n      <th>single_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>5ueUywJbmAZY2MF9hdJS2y</td>\n      <td>[\"[Verse 1]\\nI got a funny feelin'\\nThe moment...</td>\n      <td>you shouldnt kiss me like this unless you mean...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>49X0LAl6faAusYq02PRAY6</td>\n      <td>[\"Intéressé(e) par l'explication des paroles d...</td>\n      <td>lady \\n hear me tonight \\n cause my feeling \\n...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3HPx8VWi8spiBTcGeWGP7h</td>\n      <td>['[Intro]\\nThey make me sick\\nI know I feel yo...</td>\n      <td>you make me sick \\n i want you and i am hating...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>5jDnI5jmAqpvKwmpXP7VSj</td>\n      <td>[\"[Verse 1]\\nI can hear the neighbors\\nThey're...</td>\n      <td>but for the grace of god go i \\n i mustve been...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>7Hgcw6qYU1ukRdRGvEkJk3</td>\n      <td>['He promised her a new and better life out in...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  song_id  ...                                        single_text\n0  5ueUywJbmAZY2MF9hdJS2y  ...  you shouldnt kiss me like this unless you mean...\n1  49X0LAl6faAusYq02PRAY6  ...  lady \\n hear me tonight \\n cause my feeling \\n...\n2  3HPx8VWi8spiBTcGeWGP7h  ...  you make me sick \\n i want you and i am hating...\n3  5jDnI5jmAqpvKwmpXP7VSj  ...  but for the grace of god go i \\n i mustve been...\n4  7Hgcw6qYU1ukRdRGvEkJk3  ...                                                   \n\n[5 rows x 3 columns]"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O9fVeSD6D9Ym",
    "cell_id": "00003-cf66c738-da1e-4da0-9e7e-7ec1ffedca38",
    "deepnote_cell_type": "code"
   },
   "source": "pdf['single_text'] = pdf['Poem'].apply(lambda x: ' \\n '.join([l.lower().strip().translate(translator) for l in str(x).splitlines() if len(l)>0]))\n\npdf.head()\n\nsum_df = pd.DataFrame( df['single_text'] )\n\nsum_df = sum_df.append(pd.DataFrame( pdf['single_text'] ))\n\nsum_df.dropna(inplace=True)",
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SkGB1KugC90B",
    "outputId": "448e1ab2-eb75-4e0f-e6c6-37c2abee4458",
    "cell_id": "00004-6c281c50-447e-4929-8a4d-29de74a5bd33",
    "deepnote_cell_type": "code"
   },
   "source": "text_as_list = []\n\nfrequencies = {}\n\nuncommon_words = set()\n\nMIN_FREQUENCY = 7\n\nMIN_SEQ = 5\n\nBATCH_SIZE =  32\n\n\ndef extract_text(text):\n\n   global text_as_list\n\n   text_as_list += [w for w in text.split(' ') if w.strip() != '' or w == '\\n']\n\n\nsum_df['single_text'].apply( extract_text )\n\nprint('Total words: ', len(text_as_list))\n\n\nfor w in text_as_list:\n\n   frequencies[w] = frequencies.get(w, 0) + 1\n  \n\nuncommon_words = set([key for key in frequencies.keys() if frequencies[key] < MIN_FREQUENCY])\n\nwords = sorted(set([key for key in frequencies.keys() if frequencies[key] >= MIN_FREQUENCY]))\n\n\nnum_words = len(words)\n\nword_indices = dict((w, i) for i, w in enumerate(words))\n\nindices_word = dict((i, w) for i, w in enumerate(words))\n\nprint('Words with less than {} appearances: {}'.format( MIN_FREQUENCY, len(uncommon_words)))\n\nprint('Words with more than {} appearances: {}'.format( MIN_FREQUENCY, len(words)))\n\n\nvalid_seqs = []\n\nend_seq_words = []\n\nfor i in range(len(text_as_list) - MIN_SEQ ):\n\n   end_slice = i + MIN_SEQ + 1\n\n   if len( set(text_as_list[i:end_slice]).intersection(uncommon_words) ) == 0:\n\n       valid_seqs.append(text_as_list[i: i + MIN_SEQ])\n\n       end_seq_words.append(text_as_list[i + MIN_SEQ])\n      \n\nprint('Valid sequences of size {}: {}'.format(MIN_SEQ, len(valid_seqs)))\n\n\nX_train, X_test, y_train, y_test = train_test_split(valid_seqs, end_seq_words, test_size=0.02, random_state=42)\n\nprint(X_train[2:5])",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total words:  442103\nWords with less than 7 appearances: 16436\nWords with more than 7 appearances: 3385\nValid sequences of size 5: 318685\n[['gotta', 'hold', 'on', 'to', 'your'], ['\\n', 'that', 'i', 'rock', 'all'], ['\\n', 'i', 'thought', 'you', 'were']]\n"
    }
   ],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iNacnXkRDUEd",
    "cell_id": "00005-93fb7c87-3611-429d-a18f-138e9ddce34f",
    "deepnote_cell_type": "code"
   },
   "source": "# Data generator for fit and evaluate\n\ndef generator(sentence_list, next_word_list, batch_size):\n\n   index = 0\n\n   while True:\n\n       x = np.zeros((batch_size, MIN_SEQ), dtype=np.int32)\n\n       y = np.zeros((batch_size), dtype=np.int32)\n\n       for i in range(batch_size):\n\n           for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n\n               x[i, t] = word_indices[w]\n\n           y[i] = word_indices[next_word_list[index % len(sentence_list)]]\n\n           index = index + 1\n\n       yield x, y\n\n\n# Functions from keras-team/keras/blob/master/examples/lstm_text_generation.py\n\ndef sample(preds, temperature=1.0):\n\n   # helper function to sample an index from a probability array\n\n   preds = np.asarray(preds).astype('float64')\n\n   preds = np.log(preds) / temperature\n\n   exp_preds = np.exp(preds)\n\n   preds = exp_preds / np.sum(exp_preds)\n\n   probas = np.random.multinomial(1, preds, 1)\n\n   return np.argmax(probas)\n\n\ndef on_epoch_end(epoch, logs):\n\n   # Function invoked at end of each epoch. Prints generated text.\n\n   examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n\n\n   # Randomly pick a seed sequence\n\n   seed_index = np.random.randint(len(X_train+X_test))\n\n   seed = (X_train+X_test)[seed_index]\n\n\n   for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n\n       sentence = seed\n\n       examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n\n       examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n\n       examples_file.write(' '.join(sentence))\n\n\n       for i in range(50):\n\n           x_pred = np.zeros((1, MIN_SEQ))\n\n           for t, word in enumerate(sentence):\n\n               x_pred[0, t] = word_indices[word]\n\n\n           preds = model.predict(x_pred, verbose=0)[0]\n\n           next_index = sample(preds, diversity)\n\n           next_word = indices_word[next_index]\n\n\n           sentence = sentence[1:]\n\n           sentence.append(next_word)\n\n\n           examples_file.write(\" \"+next_word)\n\n       examples_file.write('\\n')\n\n   examples_file.write('='*80 + '\\n')\n\n   examples_file.flush()",
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wo0Nw8c2DWsf",
    "cell_id": "00006-9df460f5-cc38-4160-95a7-350b2a87979d",
    "deepnote_cell_type": "code"
   },
   "source": "def get_model():\n\n   print('Build model...')\n\n   model = Sequential()\n\n   model.add(Embedding(input_dim=len(words), output_dim=1024))\n\n   model.add(Bidirectional(LSTM(128)))\n\n   model.add(Dense(len(words)))\n\n   model.add(Activation('softmax'))\n\n   return model",
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s5qLvbJ7tBYl",
    "cell_id": "00007-d8f77eaf-dfdb-48ad-8e8f-8caa166019f9",
    "deepnote_cell_type": "code"
   },
   "source": "def get_model():\n\n   print('Build model...')\n\n   model = Sequential()\n\n   model.add(Embedding(input_dim=len(words), output_dim=1024))\n\n   model.add(Bidirectional(LSTM(128)))\n\n   model.add(Dense(len(words)))\n\n   model.add(Activation('softmax'))\n\n   return model",
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9caaZMCDamR",
    "outputId": "5f4ff4e9-d29c-458d-8807-fb5990aca9d8",
    "cell_id": "00008-5d6785be-5fe9-4ae7-b480-ca1911c36e2e",
    "deepnote_cell_type": "code"
   },
   "source": "model = get_model()\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n\n\nfile_path = \"/content/drive/MyDrive/RapLyrics/Trap-Male/checkpoints/LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-loss{loss:.4f}-acc{accuracy:.4f}-val_loss{val_loss:.4f}-val_acc{val_accuracy:.4f}\" %(len(words), MIN_SEQ, MIN_FREQUENCY)\n\n\ncheckpoint = ModelCheckpoint(file_path, monitor='val_accuracy', save_best_only=True)\n\nprint_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=20)\n\ncallbacks_list = [checkpoint, print_callback, early_stopping]\n\n\nexamples_file = open('examples.txt', \"w\")\n\nmodel.fit(generator(X_train, y_train, BATCH_SIZE),\n\n                   steps_per_epoch=int(len(valid_seqs)/BATCH_SIZE) + 1,\n\n                   epochs=1,\n\n                   callbacks=callbacks_list,\n\n                   validation_data=generator(X_test, y_train, BATCH_SIZE),\n\n                   validation_steps=int(len(y_train)/BATCH_SIZE) + 1)",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Build model...\n9959/9959 [==============================] - 1400s 140ms/step - loss: 4.5980 - accuracy: 0.2195 - val_loss: 7.2258 - val_accuracy: 0.0422\n"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: /content/drive/MyDrive/RapLyrics/Trap-Male/checkpoints/LSTM_LYRICS-epoch001-words3385-sequence5-minfreq7-loss4.5980-acc0.2195-val_loss7.2258-val_acc0.0422/assets\n"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:tensorflow:Assets written to: /content/drive/MyDrive/RapLyrics/Trap-Male/checkpoints/LSTM_LYRICS-epoch001-words3385-sequence5-minfreq7-loss4.5980-acc0.2195-val_loss7.2258-val_acc0.0422/assets\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f4ed9dbd750>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e1609fae-f7ed-42b7-8c74-772735f18851' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Genre=PopRap-RapLyrics-Fiverr-1Nov.ipynb",
   "provenance": [],
   "collapsed_sections": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "deepnote_notebook_id": "72376a3f-3d58-4290-89a2-2613d8241489",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}