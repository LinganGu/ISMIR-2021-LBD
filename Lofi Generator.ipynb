{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "j6fTAqAXDO_3",
    "outputId": "db721bfa-f93a-4582-92d9-c8a7e23b4786",
    "cell_id": "00000-42c6eabe-1ed1-4452-91a9-eea2d67e7adb",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "9bf652f4",
    "execution_start": 1636638429711,
    "execution_millis": 2,
    "deepnote_cell_type": "code"
   },
   "source": "import io\n\nimport os\n\nimport sys\n\nimport string\n\nimport numpy as np\n\nimport pandas as pd\n\nfrom tensorflow import keras\n\nfrom __future__ import print_function\n\nfrom tensorflow.keras.models import Sequential\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras.callbacks import LambdaCallback, ModelCheckpoint, EarlyStopping\n\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, LSTM, Bidirectional, Embedding\n\n\ntranslator = str.maketrans('', '', string.punctuation)\n\ndf = pd.read_csv(\"/content/drive/MyDrive/RapLyrics/Lofi-Male/LoFi-Male.csv\", sep=\"\\t\")\n\ndf.head()\n\n",
   "outputs": [
    {
     "output_type": "error",
     "ename": "SyntaxError",
     "evalue": "from __future__ imports must occur at the beginning of the file (<ipython-input-1-bdfccb00d3d3>, line 18)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-bdfccb00d3d3>\"\u001b[0;36m, line \u001b[0;32m18\u001b[0m\n\u001b[0;31m    \u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m from __future__ imports must occur at the beginning of the file\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 440
    },
    "id": "0PT70XEuCTWw",
    "outputId": "2f3ebb0d-49c6-4934-b01c-25aa2ed615fd",
    "cell_id": "00001-56d13887-b875-4d41-87be-188843ed6a8c",
    "deepnote_to_be_reexecuted": false,
    "source_hash": "c7399c95",
    "execution_start": 1636638429712,
    "execution_millis": 140,
    "deepnote_cell_type": "code"
   },
   "source": "pdf = pd.read_csv('/content/drive/MyDrive/RapLyrics/PoetryFoundationData.csv',quotechar='\"')\n\npdf.head()",
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-8af174646946>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive/MyDrive/RapLyrics/PoetryFoundationData.csv'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mquotechar\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "id": "AhhX7KFpD5yT",
    "outputId": "dfd78d3e-b5e1-4c6f-9ea0-da4b7d122898",
    "cell_id": "00002-db68cb72-bdca-4434-9bf0-df5173e54fc3",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "31c6409b",
    "deepnote_cell_type": "code"
   },
   "source": "def split_text(x):\n\n   text = x['lyrics']\n   x = str(x)\n\n   sections = str(text).split('\\\\n\\\\n')\n\n   keys = {'Verse 1': np.nan,'Verse 2':np.nan,'Verse 3':np.nan,'Verse 4':np.nan, 'Chorus':np.nan}\n\n   lyrics = str()\n\n   single_text = []\n\n   res = {}\n\n   for s in sections:\n\n       key = s[s.find('[') + 1:s.find(']')].strip()\n\n       if ':' in key:\n\n           key = key[:key.find(':')]\n          \n\n       if key in keys:\n\n           single_text += [x.lower().replace('(','').replace(')','').translate(translator) for x in s[s.find(']')+1:].split('\\\\n') if len(x) > 1]\n          \n\n       res['single_text'] =  ' \\n '.join(single_text)\n\n   return pd.Series(res)\n\n\ndf = df.join( df.apply(split_text, axis=1))\n\ndf.head()",
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>song_id</th>\n      <th>lyrics</th>\n      <th>single_text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>41bAbONTjBpwAai6uHSgRD</td>\n      <td>[\"[Verse 1:]\\nHello, yeah, it's been a while\\n...</td>\n      <td>im not talking about moving in \\n and i dont w...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00PLtXXER1XcTRZvs3LioS</td>\n      <td>[\"Get the funk out ma face\\nGet the funk out m...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>67J6NR2Tdl0h2epWHcCBBN</td>\n      <td>[\"So you say you tried\\nBut you just can't fin...</td>\n      <td></td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>38sXuGEGUEWOZcDNiTRmQu</td>\n      <td>[\"She's taking it easy\\nI'm taking it hard\\nSh...</td>\n      <td>shes having a time now \\n out painting the tow...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5KA5FInbzpqZ0foY5WmDTR</td>\n      <td>['[Round 1: Illmaculate]\\nThis tall motherfuck...</td>\n      <td></td>\n    </tr>\n  </tbody>\n</table>\n</div>",
      "text/plain": "                  song_id  ...                                        single_text\n0  41bAbONTjBpwAai6uHSgRD  ...  im not talking about moving in \\n and i dont w...\n1  00PLtXXER1XcTRZvs3LioS  ...                                                   \n2  67J6NR2Tdl0h2epWHcCBBN  ...                                                   \n3  38sXuGEGUEWOZcDNiTRmQu  ...  shes having a time now \\n out painting the tow...\n4  5KA5FInbzpqZ0foY5WmDTR  ...                                                   \n\n[5 rows x 3 columns]"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "O9fVeSD6D9Ym",
    "cell_id": "00003-1293ac3c-45fb-4cc7-affb-781adc0b6401",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "84fc828b",
    "deepnote_cell_type": "code"
   },
   "source": "pdf['single_text'] = pdf['Poem'].apply(lambda x: ' \\n '.join([l.lower().strip().translate(translator) for l in str(x).splitlines() if len(l)>0]))\n\npdf.head()\n\nsum_df = pd.DataFrame( df['single_text'] )\n\nsum_df = sum_df.append(pd.DataFrame( pdf['single_text'] ))\n\nsum_df.dropna(inplace=True)",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SkGB1KugC90B",
    "outputId": "ff3dfe8f-629c-476c-b1b5-22cf211edab2",
    "cell_id": "00004-510efda3-687c-485e-b329-e07861eb03d7",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "26f647c1",
    "deepnote_cell_type": "code"
   },
   "source": "text_as_list = []\n\nfrequencies = {}\n\nuncommon_words = set()\n\nMIN_FREQUENCY = 7\n\nMIN_SEQ = 5\n\nBATCH_SIZE =  32\n\n\ndef extract_text(text):\n\n   global text_as_list\n\n   text_as_list += [w for w in text.split(' ') if w.strip() != '' or w == '\\n']\n\n\nsum_df['single_text'].apply( extract_text )\n\nprint('Total words: ', len(text_as_list))\n\n\nfor w in text_as_list:\n\n   frequencies[w] = frequencies.get(w, 0) + 1\n  \n\nuncommon_words = set([key for key in frequencies.keys() if frequencies[key] < MIN_FREQUENCY])\n\nwords = sorted(set([key for key in frequencies.keys() if frequencies[key] >= MIN_FREQUENCY]))\n\n\nnum_words = len(words)\n\nword_indices = dict((w, i) for i, w in enumerate(words))\n\nindices_word = dict((i, w) for i, w in enumerate(words))\n\nprint('Words with less than {} appearances: {}'.format( MIN_FREQUENCY, len(uncommon_words)))\n\nprint('Words with more than {} appearances: {}'.format( MIN_FREQUENCY, len(words)))\n\n\nvalid_seqs = []\n\nend_seq_words = []\n\nfor i in range(len(text_as_list) - MIN_SEQ ):\n\n   end_slice = i + MIN_SEQ + 1\n\n   if len( set(text_as_list[i:end_slice]).intersection(uncommon_words) ) == 0:\n\n       valid_seqs.append(text_as_list[i: i + MIN_SEQ])\n\n       end_seq_words.append(text_as_list[i + MIN_SEQ])\n      \n\nprint('Valid sequences of size {}: {}'.format(MIN_SEQ, len(valid_seqs)))\n\n\nX_train, X_test, y_train, y_test = train_test_split(valid_seqs, end_seq_words, test_size=0.02, random_state=42)\n\nprint(X_train[2:5])",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Total words:  207749\nWords with less than 7 appearances: 13453\nWords with more than 7 appearances: 2193\nValid sequences of size 5: 116772\n[['it', 'go', '\\n', 'but', 'you'], ['\\n', 'but', 'what', 'if', 'the'], ['sugar', '\\n', 'now', 'break', 'it']]\n"
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "iNacnXkRDUEd",
    "cell_id": "00005-7ac158ad-85d2-48be-bb05-53c4366a2508",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "ae72697a",
    "deepnote_cell_type": "code"
   },
   "source": "# Data generator for fit and evaluate\n\ndef generator(sentence_list, next_word_list, batch_size):\n\n   index = 0\n\n   while True:\n\n       x = np.zeros((batch_size, MIN_SEQ), dtype=np.int32)\n\n       y = np.zeros((batch_size), dtype=np.int32)\n\n       for i in range(batch_size):\n\n           for t, w in enumerate(sentence_list[index % len(sentence_list)]):\n\n               x[i, t] = word_indices[w]\n\n           y[i] = word_indices[next_word_list[index % len(sentence_list)]]\n\n           index = index + 1\n\n       yield x, y\n\n\n# Functions from keras-team/keras/blob/master/examples/lstm_text_generation.py\n\ndef sample(preds, temperature=1.0):\n\n   # helper function to sample an index from a probability array\n\n   preds = np.asarray(preds).astype('float64')\n\n   preds = np.log(preds) / temperature\n\n   exp_preds = np.exp(preds)\n\n   preds = exp_preds / np.sum(exp_preds)\n\n   probas = np.random.multinomial(1, preds, 1)\n\n   return np.argmax(probas)\n\n\ndef on_epoch_end(epoch, logs):\n\n   # Function invoked at end of each epoch. Prints generated text.\n\n   examples_file.write('\\n----- Generating text after Epoch: %d\\n' % epoch)\n\n\n   # Randomly pick a seed sequence\n\n   seed_index = np.random.randint(len(X_train+X_test))\n\n   seed = (X_train+X_test)[seed_index]\n\n\n   for diversity in [0.3, 0.4, 0.5, 0.6, 0.7]:\n\n       sentence = seed\n\n       examples_file.write('----- Diversity:' + str(diversity) + '\\n')\n\n       examples_file.write('----- Generating with seed:\\n\"' + ' '.join(sentence) + '\"\\n')\n\n       examples_file.write(' '.join(sentence))\n\n\n       for i in range(50):\n\n           x_pred = np.zeros((1, MIN_SEQ))\n\n           for t, word in enumerate(sentence):\n\n               x_pred[0, t] = word_indices[word]\n\n\n           preds = model.predict(x_pred, verbose=0)[0]\n\n           next_index = sample(preds, diversity)\n\n           next_word = indices_word[next_index]\n\n\n           sentence = sentence[1:]\n\n           sentence.append(next_word)\n\n\n           examples_file.write(\" \"+next_word)\n\n       examples_file.write('\\n')\n\n   examples_file.write('='*80 + '\\n')\n\n   examples_file.flush()",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "wo0Nw8c2DWsf",
    "cell_id": "00006-0b5ac255-d49d-4b24-92a8-a7a163373b46",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "9bae405d",
    "deepnote_cell_type": "code"
   },
   "source": "def get_model():\n\n   print('Build model...')\n\n   model = Sequential()\n\n   model.add(Embedding(input_dim=len(words), output_dim=1024))\n\n   model.add(Bidirectional(LSTM(128)))\n\n   model.add(Dense(len(words)))\n\n   model.add(Activation('softmax'))\n\n   return model",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "s5qLvbJ7tBYl",
    "cell_id": "00007-6227bfb2-e55e-4153-86ec-2c84898d81e5",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "9bae405d",
    "deepnote_cell_type": "code"
   },
   "source": "def get_model():\n\n   print('Build model...')\n\n   model = Sequential()\n\n   model.add(Embedding(input_dim=len(words), output_dim=1024))\n\n   model.add(Bidirectional(LSTM(128)))\n\n   model.add(Dense(len(words)))\n\n   model.add(Activation('softmax'))\n\n   return model",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c9caaZMCDamR",
    "outputId": "572441c9-449b-4b7d-ee1d-ba2abc004f76",
    "cell_id": "00008-d121ed85-9af3-4140-9e4d-f447dc333b48",
    "deepnote_to_be_reexecuted": true,
    "source_hash": "7f62f864",
    "deepnote_cell_type": "code"
   },
   "source": "model = get_model()\n\nmodel.compile(loss='sparse_categorical_crossentropy', optimizer=\"adam\", metrics=['accuracy'])\n\n\nfile_path = \"/content/drive/MyDrive/RapLyrics/Trap-Male/checkpoints/LSTM_LYRICS-epoch{epoch:03d}-words%d-sequence%d-minfreq%d-loss{loss:.4f}-acc{accuracy:.4f}-val_loss{val_loss:.4f}-val_acc{val_accuracy:.4f}\" %(len(words), MIN_SEQ, MIN_FREQUENCY)\n\n\ncheckpoint = ModelCheckpoint(file_path, monitor='val_accuracy', save_best_only=True)\n\nprint_callback = LambdaCallback(on_epoch_end=on_epoch_end)\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience=20)\n\ncallbacks_list = [checkpoint, print_callback, early_stopping]\n\n\nexamples_file = open('examples.txt', \"w\")\n\nmodel.fit(generator(X_train, y_train, BATCH_SIZE),\n\n                   steps_per_epoch=int(len(valid_seqs)/BATCH_SIZE) + 1,\n\n                   epochs=1,\n\n                   callbacks=callbacks_list,\n\n                   validation_data=generator(X_test, y_train, BATCH_SIZE),\n\n                   validation_steps=int(len(y_train)/BATCH_SIZE) + 1)",
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Build model...\n3650/3650 [==============================] - 464s 126ms/step - loss: 4.8923 - accuracy: 0.1895 - val_loss: 6.7645 - val_accuracy: 0.0514\n"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "WARNING:absl:Found untraced functions such as lstm_cell_1_layer_call_fn, lstm_cell_1_layer_call_and_return_conditional_losses, lstm_cell_2_layer_call_fn, lstm_cell_2_layer_call_and_return_conditional_losses, lstm_cell_1_layer_call_fn while saving (showing 5 of 10). These functions will not be directly callable after loading.\n"
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "INFO:tensorflow:Assets written to: /content/drive/MyDrive/RapLyrics/Trap-Male/checkpoints/LSTM_LYRICS-epoch001-words2193-sequence5-minfreq7-loss4.8923-acc0.1895-val_loss6.7645-val_acc0.0514/assets\n"
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "INFO:tensorflow:Assets written to: /content/drive/MyDrive/RapLyrics/Trap-Male/checkpoints/LSTM_LYRICS-epoch001-words2193-sequence5-minfreq7-loss4.8923-acc0.1895-val_loss6.7645-val_acc0.0514/assets\n"
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<keras.callbacks.History at 0x7f19aaeb3690>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": "<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=e1609fae-f7ed-42b7-8c74-772735f18851' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>",
   "metadata": {
    "tags": [],
    "created_in_deepnote_cell": true,
    "deepnote_cell_type": "markdown"
   }
  }
 ],
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "Genre=LoFi-RapLyrics-Fiverr-1Nov.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  },
  "deepnote_notebook_id": "1d73ed3b-cd43-47e6-bada-b8ce95fb63d8",
  "deepnote": {},
  "deepnote_execution_queue": []
 }
}